import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";
import Replicate from "replicate"; 

const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY || "";
const genAI = new GoogleGenerativeAI(apiKey);

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN || "MISSING_KEY",
});

export const runtime = "edge";

export async function POST(req: Request) {
  try {
    const { messages, model, persona } = await req.json();
    const lastMessage = messages[messages.length - 1];
    const prompt = typeof lastMessage.content === 'string' ? lastMessage.content : lastMessage.content.text;

    console.log(`[API Request] Model: ${model}`);

    // ... (Replicate ç”»å›¾/è§†é¢‘é€»è¾‘ä¿æŒä¸å˜ï¼Œçœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼Œè¯·ä¿ç•™ä¹‹å‰çš„ä»£ç ) ...
    // ... å¦‚æœéœ€è¦æˆ‘å®Œæ•´å†™å‡º Replicate éƒ¨åˆ†è¯·å‘Šè¯‰æˆ‘ï¼Œå¦åˆ™åªæ›¿æ¢ä¸‹é¢çš„ Gemini éƒ¨åˆ† ...

    // ============================================================
    // ğŸ¨ åˆ†æ”¯ 1ï¼šç»˜å›¾æ¨¡å‹ (Banana SDXL)
    // ============================================================
    if (model === 'banana-sdxl') {
        // ... (ä¿æŒä¹‹å‰çš„ Replicate ç»˜å›¾ä»£ç ) ...
        if (!process.env.REPLICATE_API_TOKEN) throw new Error("Replicate API Key æœªé…ç½®");
        const output: any = await replicate.run(
          "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
          { input: { prompt: prompt, width: 1024, height: 1024, refine: "expert_ensemble_refiner" } }
        );
        return new Response(`![Generated Image](${output[0]})\n\nâœ… **ç»˜å›¾å®Œæˆï¼**\n*æ¶ˆè€—: $0.20*`);
    }

    // ============================================================
    // ğŸ¬ åˆ†æ”¯ 2ï¼šè§†é¢‘æ¨¡å‹
    // ============================================================
    if (model === 'sora-v1' || model === 'veo-google') {
        // ... (ä¿æŒä¹‹å‰çš„ Replicate è§†é¢‘ä»£ç ) ...
        if (!process.env.REPLICATE_API_TOKEN) throw new Error("Replicate API Key æœªé…ç½®");
        const videoOutput: any = await replicate.run(
          "anotherjesse/zeroscope-v2-xl:9f747673945c62801b13b84701c783929c0ee784e4748ec062204894dda1a351",
          { input: { prompt: prompt, fps: 24, width: 1024, height: 576, num_frames: 24 } }
        );
        const videoUrl = videoOutput[0];
        return new Response(`[è§†é¢‘ç”Ÿæˆå®Œæ¯•](${videoUrl})\n\n<video controls src="${videoUrl}" width="100%" style="border-radius: 12px; margin-top: 10px;"></video>\n\nâœ… **è§†é¢‘ç”ŸæˆæˆåŠŸï¼**\n*æ¶ˆè€—: $2.50*`);
    }

    // ============================================================
    // ğŸ§  åˆ†æ”¯ 3ï¼šGemini æ–‡å­—æ¨¡å‹ (ç²¾å‡†æ˜ å°„ä½ çš„ 2.5 æƒé™)
    // ============================================================
    
    let targetModel = 'gemini-2.5-flash'; // é»˜è®¤ä¿åº•

    // 1. ä½æ¡£ ($0.03) -> åˆ©æ¶¦ç‹
    if (model === 'gemini-2.0-flash-exp') {
        targetModel = 'gemini-2.5-flash'; 
    } 
    // 2. ä¸­æ¡£ ($0.05) -> ç¨³å®šè¾“å‡º
    else if (model === 'gemini-1.5-pro') {
        targetModel = 'gemini-2.5-pro';   
    } 
    // 3. é«˜æ¡£ ($0.07) -> æ€è€ƒè€… (Exp 1206)
    else if (model === 'gemini-2.0-flash-thinking-exp') {
        targetModel = 'gemini-exp-1206'; 
    }

    let systemInstruction = "You are Eureka, a helpful AI assistant.";
    
    // å¦‚æœæ˜¯ Exp-1206 (Thinking)ï¼Œå®ƒè‡ªå¸¦ thinking èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬å¯ä»¥å¼•å¯¼å®ƒæ›´æ·±å…¥
    if (targetModel === 'gemini-exp-1206') {
        systemInstruction += " You are in Deep Thinking Mode. Analyze the user's request thoroughly using Chain of Thought before answering.";
    }
    
    if (persona === 'tiktok_script') systemInstruction += " You are a TikTok viral script expert.";

    const geminiModel = genAI.getGenerativeModel({ 
      model: targetModel, 
      systemInstruction: systemInstruction 
    });

    const chat = geminiModel.startChat({
      history: messages.slice(0, -1).map((m: any) => ({
        role: m.role === 'user' ? 'user' : 'model',
        parts: [{ text: typeof m.content === 'string' ? m.content : m.content.text }],
      })),
    });

    const currentContent = messages[messages.length - 1].content;
    let result;
    
    if (typeof currentContent === 'object' && currentContent.images && currentContent.images.length > 0) {
      const imageParts = currentContent.images.map((img: string) => ({
        inlineData: { data: img.split(",")[1], mimeType: "image/jpeg" },
      }));
      result = await geminiModel.generateContentStream([currentContent.text, ...imageParts]);
    } else {
      result = await chat.sendMessageStream(typeof currentContent === 'string' ? currentContent : currentContent.text);
    }

    const stream = new ReadableStream({
      async start(controller) {
        try {
            for await (const chunk of result.stream) {
              const chunkText = chunk.text();
              if (chunkText) controller.enqueue(new TextEncoder().encode(chunkText));
            }
            controller.close();
        } catch (e) {
            console.error("Stream error:", e);
            controller.close();
        }
      },
    });

    return new Response(stream);

  } catch (error: any) {
    console.error("Chat Route Error:", error);
    let userMsg = "æœåŠ¡æš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚";
    if (error.toString().includes("402")) userMsg = "Replicate ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼ã€‚";
    return new Response(`âŒ **è¯·æ±‚å¤±è´¥**\n\n${userMsg}\n\n*Debug info: ${error.message}*`);
  }
}