import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";
import Replicate from "replicate"; 

const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY || "";
const genAI = new GoogleGenerativeAI(apiKey);

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN || "MISSING_KEY",
});

// âœ… ä¿æŒ Node.js ç¯å¢ƒ + 300ç§’è¶…æ—¶ (Pro ä¸“å±)
export const runtime = "nodejs"; 
export const maxDuration = 300; 
export const dynamic = 'force-dynamic';

export async function POST(req: Request) {
  const startTime = Date.now(); 
  console.log(`[API Start] Request received`);

  try {
    const { messages, model, persona } = await req.json();
    const lastMessage = messages[messages.length - 1];
    const prompt = typeof lastMessage.content === 'string' ? lastMessage.content : lastMessage.content.text;

    // ============================================================
    // ğŸ¨ åˆ†æ”¯ 1ï¼šç»˜å›¾æ¨¡å‹ (Banana SDXL)
    // ============================================================
    if (model === 'banana-sdxl') {
        if (!process.env.REPLICATE_API_TOKEN) throw new Error("Replicate API Key æœªé…ç½®");
        const output: any = await replicate.run(
          "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
          { input: { prompt: prompt, width: 1024, height: 1024, refine: "expert_ensemble_refiner" } }
        );
        // å›¾ç‰‡ç»§ç»­ä½¿ç”¨ JSON è¿”å› URLï¼Œå› ä¸ºå›¾ç‰‡é€šå¸¸æ²¡æœ‰ä¸¥é‡çš„è·¨åŸŸæ’­æ”¾é—®é¢˜
        return NextResponse.json({ 
            type: 'image', 
            url: output[0], 
            markdown: `![Generated Image](${output[0]})\n\nâœ… **ç»˜å›¾å®Œæˆï¼**` 
        });
    }

    // ============================================================
    // ğŸ¬ åˆ†æ”¯ 2ï¼šè§†é¢‘æ¨¡å‹ (å…³é”®ä¿®å¤ï¼šæœåŠ¡å™¨ä»£ç†ä¸‹è½½)
    // ============================================================
    if (model === 'sora-v1' || model === 'veo-google') {
        if (!process.env.REPLICATE_API_TOKEN) throw new Error("Replicate API Key æœªé…ç½®");
        
        console.log(`[API Video] Starting generation...`);
        
        // 1. è°ƒç”¨ Replicate ç”Ÿæˆè§†é¢‘ (é«˜æ¸…å‚æ•°)
        const videoOutput: any = await replicate.run(
          "anotherjesse/zeroscope-v2-xl:9f747673945c62801b13b84701c783929c0ee784e4748ec062204894dda1a351",
          { 
            input: { 
              prompt: prompt, 
              fps: 24, 
              width: 1024,   
              height: 576,   
              num_frames: 24 
            } 
          }
        );
        
        const remoteUrl = videoOutput[0];
        console.log(`[API Video] Generated Remote URL: ${remoteUrl}`);

        // 2. å…³é”®æ­¥éª¤ï¼šæœåŠ¡å™¨ç«¯ä¸‹è½½è§†é¢‘æµ
        // ä¸ç›´æ¥è¿”å› URLï¼Œè€Œæ˜¯ç”± Vercel å»è¯·æ±‚è¿™ä¸ªæ–‡ä»¶ï¼Œç„¶åé€ä¼ ç»™å‰ç«¯
        // è¿™æ ·å¯ä»¥è§£å†³æ‰€æœ‰è·¨åŸŸ(CORS)å’Œä¸‹è½½æƒé™é—®é¢˜
        const videoRes = await fetch(remoteUrl);
        
        if (!videoRes.ok) throw new Error("Failed to fetch video stream from source");

        // 3. å°†è§†é¢‘æµè¿”å›ç»™å‰ç«¯ï¼Œæ ‡è®°ä¸º video/mp4
        return new Response(videoRes.body, {
            headers: {
                'Content-Type': 'video/mp4',
                'Content-Disposition': 'attachment; filename="video.mp4"',
            }
        });
    }

    // ============================================================
    // ğŸ§  åˆ†æ”¯ 3ï¼šGemini æ–‡å­—æ¨¡å‹ (ä¿æŒåŸæœ‰æµå¼é€»è¾‘)
    // ============================================================
    
    let targetModel = 'gemini-2.5-flash'; 
    if (model === 'gemini-2.0-flash-exp') targetModel = 'gemini-2.5-flash'; 
    else if (model === 'gemini-1.5-pro') targetModel = 'gemini-2.5-pro';   
    else if (model === 'gemini-exp-1206' || model === 'gemini-2.0-flash-thinking-exp') targetModel = 'gemini-exp-1206'; 

    let systemInstruction = `You are Eureka, a helpful AI assistant. 
    IMPORTANT: After your main response, you MUST generate 3 related follow-up questions.
    Format: ___RELATED___ Question 1? | Question 2? | Question 3?`;
    
    if (model === 'gemini-exp-1206') systemInstruction += " You are in Deep Thinking Mode.";

    const geminiModel = genAI.getGenerativeModel({ 
      model: targetModel, 
      systemInstruction: systemInstruction,
      tools: [{ googleSearch: {} } as any] 
    });

    const chat = geminiModel.startChat({
      history: messages.slice(0, -1).map((m: any) => ({
        role: m.role === 'user' ? 'user' : 'model',
        parts: [{ text: typeof m.content === 'string' ? m.content : m.content.text }],
      })),
    });

    const currentContent = messages[messages.length - 1].content;
    let result;
    
    if (typeof currentContent === 'object' && currentContent.images && currentContent.images.length > 0) {
      const imageParts = currentContent.images.map((img: string) => ({
        inlineData: { data: img.split(",")[1], mimeType: "image/jpeg" },
      }));
      result = await geminiModel.generateContentStream([currentContent.text, ...imageParts]);
    } else {
      result = await chat.sendMessageStream(typeof currentContent === 'string' ? currentContent : currentContent.text);
    }

    const stream = new ReadableStream({
      async start(controller) {
        try {
            for await (const chunk of result.stream) {
              const chunkText = chunk.text();
              if (chunkText) controller.enqueue(new TextEncoder().encode(chunkText));
            }
            controller.close();
        } catch (e) {
            controller.close();
        }
      },
    });

    return new Response(stream);

  } catch (error: any) {
    console.error("API Error:", error);
    let userMsg = "æœåŠ¡æš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚";
    if (error.toString().includes("402")) userMsg = "é¢åº¦ä¸è¶³ï¼Œè¯·å……å€¼ã€‚";
    if (error.toString().includes("429")) userMsg = "è°ƒç”¨å¤ªé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•ã€‚"; 
    
    // å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œè¿”å› JSON æ ¼å¼çš„é”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿å‰ç«¯è¯†åˆ«
    return NextResponse.json({ error: userMsg, details: error.message }, { status: 500 });
  }
}