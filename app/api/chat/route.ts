import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";
import Replicate from "replicate"; 

const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY || "";
const genAI = new GoogleGenerativeAI(apiKey);

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN || "MISSING_KEY",
});

// âœ… è®¾ç½® Node.js è¿è¡Œç¯å¢ƒ
export const runtime = "nodejs"; 
// âœ… å°è¯•æ”¾å®½å‡½æ•°è¶…æ—¶æ—¶é—´ (Proè´¦å·æœ‰æ•ˆ)
export const maxDuration = 300; 
export const dynamic = 'force-dynamic';

// ---------------------------------------------------------
// 1. GET æ–¹æ³•ï¼šä¸“é—¨ç”¨äºå‰ç«¯è½®è¯¢æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
// ---------------------------------------------------------
export async function GET(req: Request) {
    const { searchParams } = new URL(req.url);
    const id = searchParams.get('id');
    
    if (!id) return NextResponse.json({ error: 'Missing ID' }, { status: 400 });

    try {
        // å» Replicate æŸ¥ä¸€ä¸‹ä»»åŠ¡ç°åœ¨çš„çŠ¶æ€
        const prediction = await replicate.predictions.get(id);
        
        // åªæœ‰å½“ä»»åŠ¡æˆåŠŸæˆ–å¤±è´¥æ—¶ï¼Œæ‰ç®—ç»“æŸ
        return NextResponse.json({
            id: prediction.id,
            status: prediction.status, // starting, processing, succeeded, failed
            output: prediction.output,
            error: prediction.error
        });
    } catch (e: any) {
        return NextResponse.json({ error: e.message }, { status: 500 });
    }
}

// ---------------------------------------------------------
// 2. POST æ–¹æ³•ï¼šåˆ›å»ºä»»åŠ¡ (ç«‹å³è¿”å› IDï¼Œä¸å‚»ç­‰)
// ---------------------------------------------------------
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const { messages, model, aspectRatio, resolution, duration, image } = body;
    const lastMessage = messages[messages.length - 1];
    const prompt = typeof lastMessage.content === 'string' ? lastMessage.content : lastMessage.content.text;

    // ============================================================
    // ğŸ¬ è§†é¢‘ç”Ÿæˆ (å¼‚æ­¥æ¨¡å¼ - è§£å†³ 504 è¶…æ—¶)
    // ============================================================
    if (model === 'sora-v1' || model === 'veo-google') {
        if (!process.env.REPLICATE_API_TOKEN) throw new Error("Replicate API Key æœªé…ç½®");
        
        let prediction;

        // ğŸ‘‰ æ¨¡å¼ Aï¼šå›¾ç”Ÿè§†é¢‘ (Image-to-Video)
        if (image) {
            console.log("ğŸš€ Creating SVD Image-to-Video Task...");
            // ä½¿ç”¨ SVD 1.1 å®˜æ–¹éªŒè¯è¿‡çš„ Hashï¼Œä¿®å¤ 422 é”™è¯¯
            prediction = await replicate.predictions.create({
                version: "3f0457e4619daac51203dedb472816f3af343739541c338029d5006d99723225", // SVD XT 1.1
                input: {
                    input_image: image,
                    video_length: "14_frames_with_svd_xt", // æ›´åŠ ç¨³å®šçš„å¸§æ•°è®¾ç½®
                    sizing_strategy: "maintain_aspect_ratio",
                    frames_per_second: 6,
                    motion_bucket_id: 127,
                    cond_aug: 0.02
                }
            });
        } 
        // ğŸ‘‰ æ¨¡å¼ Bï¼šæ–‡ç”Ÿè§†é¢‘ (Text-to-Video)
        else {
            console.log("ğŸš€ Creating Zeroscope Text-to-Video Task...");
            // Zeroscope XL
            prediction = await replicate.predictions.create({
                version: "9f747673945c62801b13b84701c783929c0ee784e4748ec062204894dda1a351",
                input: {
                    prompt: prompt,
                    num_frames: 24, // ä¿æŒé»˜è®¤ä»¥ç¡®ä¿ç¨³å®šæ€§
                    width: 1024,
                    height: 576,
                    fps: 24
                }
            });
        }

        // âš¡ï¸ å…³é”®ï¼šç«‹å³è¿”å›ä»»åŠ¡ IDï¼Œè®©å‰ç«¯å»è½®è¯¢
        return NextResponse.json({ 
            type: 'async_job', 
            id: prediction.id, 
            status: prediction.status 
        });
    }

    // ============================================================
    // ğŸ¨ å›¾ç‰‡ç”Ÿæˆ (åŒæ­¥æ¨¡å¼ - å› ä¸ºå¾ˆå¿«)
    // ============================================================
    if (model === 'banana-sdxl') {
        const output: any = await replicate.run(
          "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
          { input: { prompt: prompt, width: 1024, height: 1024, refine: "expert_ensemble_refiner" } }
        );
        return new Response(`![Generated Image](${output[0]})\n\nâœ… **ç»˜å›¾å®Œæˆï¼**`);
    }

    // ============================================================
    // ğŸ§  èŠå¤©æ¨¡å‹ (Gemini - æµå¼)
    // ============================================================
    let targetModel = 'gemini-2.5-flash'; 
    if (model === 'gemini-2.0-flash-exp') targetModel = 'gemini-2.5-flash'; 
    
    let systemInstruction = `You are Eureka. IMPORTANT: Generate 3 related questions at the end: ___RELATED___ Q1 | Q2 | Q3`;
    if (model === 'gemini-exp-1206') systemInstruction += " Deep Thinking Mode.";

    const geminiModel = genAI.getGenerativeModel({ model: targetModel, systemInstruction });
    const chat = geminiModel.startChat({
      history: messages.slice(0, -1).map((m: any) => ({
        role: m.role === 'user' ? 'user' : 'model',
        parts: [{ text: typeof m.content === 'string' ? m.content : m.content.text }],
      })),
    });

    const currentContent = messages[messages.length - 1].content;
    let result;
    
    if (typeof currentContent === 'object' && currentContent.images?.length > 0) {
      const imageParts = currentContent.images.map((img: string) => ({
        inlineData: { data: img.split(",")[1], mimeType: "image/jpeg" },
      }));
      result = await geminiModel.generateContentStream([currentContent.text, ...imageParts]);
    } else {
      result = await chat.sendMessageStream(typeof currentContent === 'string' ? currentContent : currentContent.text);
    }

    const stream = new ReadableStream({
      async start(controller) {
        try {
            for await (const chunk of result.stream) {
              const chunkText = chunk.text();
              if (chunkText) controller.enqueue(new TextEncoder().encode(chunkText));
            }
            controller.close();
        } catch (e) {
            controller.close();
        }
      },
    });

    return new Response(stream);

  } catch (error: any) {
    console.error("API Error:", error);
    // è¿”å› JSON æ ¼å¼é”™è¯¯ä»¥ä¾¿å‰ç«¯å±•ç¤º
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}